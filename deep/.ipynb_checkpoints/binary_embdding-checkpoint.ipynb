{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i like cats', 'i like dogs', 'we like cats', 'we like dogs', 'he likes cats', 'he likes dogs', 'she likes cats', 'she likes dogs']\n",
      "[(['like', 'cats'], 'i'), (['i', 'cats'], 'like'), (['like', 'i'], 'cats'), (['like', 'dogs'], 'i'), (['i', 'dogs'], 'like'), (['like', 'i'], 'dogs'), (['like', 'cats'], 'we'), (['we', 'cats'], 'like'), (['like', 'we'], 'cats'), (['like', 'dogs'], 'we'), (['we', 'dogs'], 'like'), (['like', 'we'], 'dogs'), (['likes', 'cats'], 'he'), (['he', 'cats'], 'likes'), (['likes', 'he'], 'cats'), (['likes', 'dogs'], 'he'), (['he', 'dogs'], 'likes'), (['likes', 'he'], 'dogs'), (['likes', 'cats'], 'she'), (['she', 'cats'], 'likes'), (['likes', 'she'], 'cats'), (['likes', 'dogs'], 'she'), (['she', 'dogs'], 'likes'), (['likes', 'she'], 'dogs')]\n",
      "3 8 <type 'str'> 111\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"I like cats\n",
    "I like dogs\n",
    "we like cats\n",
    "we like dogs\n",
    "he likes cats\n",
    "he likes dogs\n",
    "she likes cats\n",
    "she likes dogs\"\"\".lower().split(\"\\n\") \n",
    "print raw_text\n",
    "\n",
    "data = []\n",
    "vocab = []\n",
    "for sentence in raw_text:\n",
    "    words = sentence.split()\n",
    "    for i, word in enumerate(words):\n",
    "        vocab.append(word)\n",
    "        if i == 0:\n",
    "            context = [words[i+1], words[i+2]]\n",
    "        elif i == len(words) - 1:\n",
    "            context = [words[i-1], words[i-2]]\n",
    "        else:\n",
    "            context = [words[i-1], words[i+1]]\n",
    "        data.append((context, word))\n",
    "        \n",
    "vocab = set(vocab)\n",
    "\n",
    "w2i = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "print data\n",
    "nwords = len(w2i)\n",
    "nbits = len(np.binary_repr(nwords-1))\n",
    "print nbits, nwords, type(np.binary_repr(nwords-1)),np.binary_repr(nwords-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 1.0, 0.0], [1.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "pos_words = data[1][0]\n",
    "word_repr = [[float(y) for y in np.binary_repr(w2i[x]).zfill(nbits)] for x in pos_words]\n",
    "word_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6789, 0.7762, 0.2728], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BinaryEmbed(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, nbits):\n",
    "        super(BinaryEmbed, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = torch.nn.Linear(2*embedding_dim, nbits) #2 because our window size is 1\n",
    "    def forward(self, inputs):\n",
    "        embed = torch.cat((self.embedding(inputs[0]), self.embedding(inputs[1])))\n",
    "        return torch.sigmoid(self.linear(embed))\n",
    "    \n",
    "b = BinaryEmbed(8, 2, 3)\n",
    "b(torch.tensor([3,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999 1.36492860317\n",
      "9999 1.16079640388\n",
      "14999 0.926463186741\n",
      "19999 0.746452689171\n",
      "24999 0.554771780968\n",
      "29999 0.206861525774\n",
      "34999 0.614300370216\n",
      "39999 0.454041272402\n",
      "44999 0.731417953968\n",
      "49999 0.777692198753\n",
      "54999 0.5702688694\n",
      "59999 0.0409789718688\n",
      "64999 0.6044896245\n",
      "69999 0.0312567800283\n",
      "74999 0.829018652439\n",
      "79999 0.0228183548898\n",
      "84999 0.783381581306\n",
      "89999 0.866666316986\n",
      "94999 0.0153988786042\n",
      "99999 0.748439192772\n"
     ]
    }
   ],
   "source": [
    "model = BinaryEmbed(nwords, 3, nbits)\n",
    "criterion = torch.nn.BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "for t in range(100000):\n",
    "    random.shuffle(data)\n",
    "    words = [torch.tensor(w2i[x]) for x in data[0][0]]\n",
    "    y_pred = model(words)\n",
    "    loss = criterion(y_pred, torch.tensor([float(y) for y in np.binary_repr(w2i[data[0][1]]).zfill(nbits)]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (t+1)%5000 == 0:\n",
    "        print t, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['likes', 'cats'], 'she')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5094, 0.9760, 0.9944], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print data[0]\n",
    "words = [torch.tensor(w2i[x]) for x in data[0][0]]\n",
    "model(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 4,\n",
       " 'dogs': 6,\n",
       " 'he': 7,\n",
       " 'i': 2,\n",
       " 'like': 1,\n",
       " 'likes': 5,\n",
       " 'she': 3,\n",
       " 'we': 0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
