{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.0269, -0.7684, -0.0047]]),\n",
       " tensor([[ 1.0225,  0.2555, -0.7867]]),\n",
       " tensor([[1.2509, 0.7152, 0.4489]]),\n",
       " tensor([[ 0.1487, -0.2523, -0.0829]]),\n",
       " tensor([[0.0560, 0.9337, 0.7852]])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = torch.nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2436, -0.1457, -0.4095]]], grad_fn=<CatBackward>)\n",
      "tensor([[-0.2436, -0.1457, -0.4095]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "lstm = torch.nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "inputs\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = None\n",
    "\n",
    "for i in inputs:\n",
    "    if hidden:\n",
    "        out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    else:\n",
    "        out, hidden = lstm(i.view(1, 1, -1))\n",
    "print out\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "out, hidden = lstm(inputs)\n",
    "print out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['everybody', 'ate', 'apple', 'that', 'read', 'dog', 'book', 'the'])\n",
      "{'everybody': 1, 'ate': 2, 'apple': 3, 'that': 4, 'read': 5, 'dog': 6, 'PADDING': 0, 'book': 7, 'the': 8}\n",
      "[[8, 6, 2, 8, 3, 0], [1, 5, 4, 7, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    (\"The dog ate the apple\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".lower().split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "vocab = set(reduce(lambda x, y : x+y, [t[0] for t in training_data] ) )\n",
    "print vocab\n",
    "word_to_ix = {word: i+1 for i, word in enumerate(vocab)}\n",
    "word_to_ix[\"PADDING\"] = 0\n",
    "tag_to_ix = {\"DET\": 1, \"NN\": 2, \"V\": 3, \"PADDING\":0}\n",
    "max_sentence_length = max([len(t[0]) for t in training_data]) + 1 #plus one for some extra protection\n",
    "training_sentences = []\n",
    "training_tags = []\n",
    "for t in training_data:\n",
    "    words, tags = t\n",
    "    training_sentences.append([0 for i in xrange(max_sentence_length)])\n",
    "    training_tags.append([0 for i in xrange(max_sentence_length)])\n",
    "    for j, word in enumerate(words):\n",
    "\n",
    "        training_sentences[-1][j] = word_to_ix[word]\n",
    "        training_tags[-1][j] = tag_to_ix[tags[j]]\n",
    "        \n",
    "print(word_to_ix)\n",
    "print training_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1534, -0.7874, -1.4722]],\n",
       "\n",
       "        [[-1.1669, -0.7750, -1.4785]],\n",
       "\n",
       "        [[-1.1825, -0.7322, -1.5482]],\n",
       "\n",
       "        [[-1.1703, -0.7501, -1.5260]],\n",
       "\n",
       "        [[-1.1532, -0.7662, -1.5160]],\n",
       "\n",
       "        [[-1.1954, -0.7654, -1.4599]]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, sentence_length):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sentence_length = sentence_length\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input).view(self.sentence_length,1,-1)\n",
    "        out, hidden = self.lstm(embedded)\n",
    "        out = self.hidden2tag(out)\n",
    "        return F.log_softmax(out, dim=2)\n",
    "    \n",
    "lstm = LSTMTagger(4, 4, len(vocab)+1, 3, max_sentence_length)\n",
    "lstm(torch.tensor(training_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 0.435446375627\n",
      "399 0.00839321744977\n",
      "599 0.00338593649911\n",
      "799 0.00184002554597\n",
      "999 0.00110415017567\n"
     ]
    }
   ],
   "source": [
    "step_size = 200\n",
    "lstm = LSTMTagger(4, 4, len(vocab)+1, 4, max_sentence_length)\n",
    "loss_fn = torch.nn.NLLLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-2)\n",
    "\n",
    "total_losses = 0\n",
    "for t in range(1000):\n",
    "\n",
    "\n",
    "    for i, data in enumerate(training_data): \n",
    "        _, tags = data\n",
    "        lstm.zero_grad()\n",
    "        output = lstm(torch.tensor(training_sentences[i])).view(max_sentence_length,-1)\n",
    "\n",
    "        loss = loss_fn(output, torch.tensor(training_tags[i]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_losses += loss.item()\n",
    "    if t%step_size == step_size - 1:\n",
    "        print t, total_losses/step_size\n",
    "        total_losses = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_sentence = \"Everybody that ate the dog read\".lower().split()\n",
    "    test = [0 for _ in range(max_sentence_length)]\n",
    "    for i, word in enumerate(test_sentence):\n",
    "        test[i] = word_to_ix[word]\n",
    "    output = lstm(torch.tensor(test))\n",
    "    print torch.argmax(output, dim = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# On Off Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6945]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OOGate(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(OOGate, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        #self.lstm = torch.nn.LSTM(1, hidden_dim)\n",
    "        self.input2hidden = torch.nn.Linear(1+hidden_dim, hidden_dim)\n",
    "        self.hidden2out = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.init_hidden()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = torch.cat((input.view(1,1,-1), self.hidden), dim = 2)\n",
    "        self.hidden = torch.tanh(self.input2hidden(input))\n",
    "        # print input, self.hidden\n",
    "        #out, self.hidden = self.lstm(input.view(1,1,1) , self.hidden)\n",
    "        out = self.hidden2out(self.hidden)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        self.hidden = torch.zeros(1, 1, self.hidden_dim)\n",
    "    \n",
    "oog = OOGate(2)\n",
    "oog(torch.tensor([1.]))\n",
    "oog(torch.tensor([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 9.48629769504\n",
      "199 1.26617297471\n",
      "299 0.994643369913\n",
      "399 0.876655199528\n",
      "499 0.858393005729\n",
      "599 0.80405915767\n",
      "699 0.804524154067\n",
      "799 0.803903802931\n",
      "899 0.766505013257\n",
      "999 0.772753817141\n",
      "1099 0.752951097488\n",
      "1199 0.786715562046\n",
      "1299 0.681298845261\n",
      "1399 0.793822412789\n",
      "1499 0.777228438556\n",
      "1599 0.745934744179\n",
      "1699 0.733000632226\n",
      "1799 0.763534942269\n",
      "1899 0.741612895131\n",
      "1999 0.764834470749\n",
      "2099 0.726180863976\n",
      "2199 0.757913743854\n",
      "2299 0.746083149016\n",
      "2399 0.741460702121\n",
      "2499 0.745916709602\n",
      "2599 0.749795624614\n",
      "2699 0.75549913168\n",
      "2799 0.754217931032\n",
      "2899 0.725392879248\n",
      "2999 0.733314616978\n",
      "3099 0.742916531265\n",
      "3199 0.751228345931\n",
      "3299 0.732059198916\n",
      "3399 0.73889634937\n",
      "3499 0.710037486255\n",
      "3599 0.729008285701\n",
      "3699 0.740915071666\n",
      "3799 0.738084877431\n",
      "3899 0.740829059482\n",
      "3999 0.737211439013\n",
      "4099 0.750723884404\n",
      "4199 0.743137818873\n",
      "4299 0.728881320953\n",
      "4399 0.750462110639\n",
      "4499 0.736233894229\n",
      "4599 0.701864287108\n",
      "4699 0.75448761344\n",
      "4799 0.730128076375\n",
      "4899 0.739888499677\n",
      "4999 0.721907474101\n",
      "5099 0.756245774329\n",
      "5199 0.735367813408\n",
      "5299 0.73769330442\n",
      "5399 0.726184356362\n",
      "5499 0.739117992222\n",
      "5599 0.725966597795\n",
      "5699 0.722977099121\n",
      "5799 0.73181257695\n",
      "5899 0.744360625148\n",
      "5999 0.741804155707\n",
      "6099 0.745859976411\n",
      "6199 0.73259403348\n",
      "6299 0.716145278215\n",
      "6399 0.735119857192\n",
      "6499 0.728522827029\n",
      "6599 0.686826482415\n",
      "6699 0.715073170066\n",
      "6799 0.709074639827\n",
      "6899 0.752504290342\n",
      "6999 0.728190897405\n",
      "7099 0.736460074484\n",
      "7199 0.730402899384\n",
      "7299 0.741437942684\n",
      "7399 0.747365014553\n",
      "7499 0.733820072114\n",
      "7599 0.728565527201\n",
      "7699 0.697038920522\n",
      "7799 0.738700692952\n",
      "7899 0.721661032438\n",
      "7999 0.740252246857\n",
      "8099 0.733231003582\n",
      "8199 0.734886145294\n",
      "8299 0.728983105123\n",
      "8399 0.731638948321\n",
      "8499 0.738687928319\n",
      "8599 0.708956424892\n",
      "8699 0.738205404878\n",
      "8799 0.731356671751\n",
      "8899 0.701826069057\n",
      "8999 0.711757307947\n",
      "9099 0.720800455511\n",
      "9199 0.716182225347\n",
      "9299 0.734108689725\n",
      "9399 0.733329879642\n",
      "9499 0.704062868953\n",
      "9599 0.728955096602\n",
      "9699 0.723156456649\n",
      "9799 0.715629440546\n",
      "9899 0.71478846997\n",
      "9999 0.714709588587\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "possibilities = [0.0 for i in range(128)]\n",
    "for i in range(128):\n",
    "    j = i%4\n",
    "    if j < 2: \n",
    "        possibilities[i] = 1.0\n",
    "        \n",
    "step_size = 100\n",
    "oog = OOGate(4)\n",
    "\n",
    "loss_fn = torch.nn.BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(oog.parameters(), lr=1e-2)\n",
    "\n",
    "total_losses = 0\n",
    "for t in range(10000):\n",
    "    \n",
    "    while True:\n",
    "        a = random.randint(0,127)\n",
    "        b = random.randint(0,126)\n",
    "        if a < b:\n",
    "            try:\n",
    "                example = possibilities[a:b+1]\n",
    "                break\n",
    "            except IndexError:\n",
    "                pass\n",
    "    # print example\n",
    "    oog.zero_grad()\n",
    "    oog.init_hidden()\n",
    "    loss = torch.tensor([0.])\n",
    "    # print example\n",
    "    for i in range(len(example) -1): \n",
    "        # print \"i\", i, data\n",
    "        oog.zero_grad()\n",
    "        output = oog(torch.tensor([example[i]]))\n",
    "        y = example[i+1]\n",
    "        \n",
    "        loss += loss_fn(output, torch.tensor([[y]]))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_losses += loss.item()\n",
    "    if t%step_size == step_size - 1:\n",
    "        print t, total_losses/step_size\n",
    "        total_losses = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([[[0.5341]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0011]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0002]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9999]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9999]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0002]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0002]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9999]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9999]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0002]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0002]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9999]]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "oog.init_hidden()\n",
    "print 1, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
