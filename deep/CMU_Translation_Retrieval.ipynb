{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 31\n",
      "2153 2056\n"
     ]
    }
   ],
   "source": [
    "# format of files: each line is \"word1 word2 ...\" aligned line-by-line\n",
    "train_src_file = \"data/parallel/train.ja\"\n",
    "train_trg_file = \"data/parallel/train.en\"\n",
    "dev_src_file = \"data/parallel/dev.ja\"\n",
    "dev_trg_file = \"data/parallel/dev.en\"\n",
    "\n",
    "w2i_src = defaultdict(lambda: len(w2i_src))\n",
    "w2i_src[\"<s>\"]\n",
    "w2i_trg = defaultdict(lambda: len(w2i_trg))\n",
    "w2i_trg[\"<s>\"]\n",
    "\n",
    "\n",
    "MAX_SRC_LENGTH = -1\n",
    "MAX_TRG_LENGTH = -1\n",
    "def read(fname_src, fname_trg, tot = 1024):\n",
    "    \"\"\"\n",
    "    Read parallel files where each line lines up\n",
    "    \"\"\"\n",
    "    global MAX_SRC_LENGTH\n",
    "    global MAX_TRG_LENGTH\n",
    "    with open(fname_src, \"r\") as f_src, open(fname_trg, \"r\") as f_trg:\n",
    "        i = 0\n",
    "        for line_src, line_trg in zip(f_src, f_trg):\n",
    "            if i > tot - 1:\n",
    "                break\n",
    "            i += 1\n",
    "            sent_src = [w2i_src[x] for x in line_src.strip().split()]\n",
    "            MAX_SRC_LENGTH = max(len(sent_src), MAX_SRC_LENGTH)\n",
    "            sent_trg = [w2i_trg[x] for x in line_trg.strip().split()]\n",
    "            MAX_TRG_LENGTH = max(len(sent_trg), MAX_TRG_LENGTH)\n",
    "            yield (sent_src, sent_trg)\n",
    "\n",
    "# Read the data\n",
    "train = list(read(train_src_file, train_trg_file))\n",
    "unk_src = w2i_src[\"<unk>\"]\n",
    "w2i_src = defaultdict(lambda: unk_src, w2i_src)\n",
    "unk_trg = w2i_trg[\"<unk>\"]\n",
    "w2i_trg = defaultdict(lambda: unk_trg, w2i_trg)\n",
    "nwords_src = len(w2i_src)\n",
    "nwords_trg = len(w2i_trg)\n",
    "#dev = list(read(dev_src_file, dev_trg_file, 512))\n",
    "print MAX_SRC_LENGTH, MAX_TRG_LENGTH\n",
    "print nwords_src, nwords_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([10, 11, 12, 13, 14, 15, 16, 7, 2, 17, 18, 19, 20, 21, 22, 6, 9],\n",
       "  [7, 8, 9, 10, 11, 12, 13, 14, 6]),\n",
       " 1024)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1], len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ステーキ は 中位 で 焼 い て くださ い 。\n",
      "i like my steak medium .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_print(fname_src, fname_trg):\n",
    "    \"\"\"\n",
    "    Read parallel files where each line lines up\n",
    "    \"\"\"\n",
    "    with open(fname_src, \"r\") as f_src, open(fname_trg, \"r\") as f_trg:\n",
    "        for line_src, line_trg in zip(f_src, f_trg):\n",
    "            print line_src, line_trg\n",
    "            break\n",
    "read_print(train_src_file, train_trg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [1, 1],\n",
      "        [2, 2]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0807, -0.1007, -0.1942, -0.0205],\n",
       "          [-0.0807, -0.1007, -0.1942, -0.0205]]], grad_fn=<ViewBackward>),\n",
       " tensor([[[ 0.0066,  0.5216, -0.2422, -0.1972],\n",
       "          [ 0.0460,  0.4311, -0.2423, -0.2371]]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "\n",
    "class TranslationRetrieval(torch.nn.Module):\n",
    "    def __init__(self, src_vocab_len, trg_vocab_len, embedding_dim, hidden_dim, batch_size):\n",
    "        super(TranslationRetrieval, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.src_embed = torch.nn.Embedding(src_vocab_len, embedding_dim, padding_idx = 0)\n",
    "        self.trg_embed = torch.nn.Embedding(trg_vocab_len, embedding_dim, padding_idx = 0)\n",
    "        self.src_lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.trg_lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.src_hidden = None\n",
    "        self.trg_hidden = None\n",
    "        \n",
    "        self.initialize()\n",
    "        \n",
    "        \n",
    "    def forward(self, src_inputs, trg_inputs):\n",
    "        \n",
    "        src_embed = self.src_embed(src_inputs)\n",
    "        trg_embed = self.trg_embed(trg_inputs)\n",
    "        \n",
    "        src_output, src_hidden = self.src_lstm(src_embed, self.src_hidden)\n",
    "        src_out, _ = src_hidden\n",
    "        trg_output, trg_hidden = self.trg_lstm(trg_embed, self.trg_hidden)\n",
    "        trg_out, _ = trg_hidden\n",
    "        return src_out, trg_out\n",
    "        \n",
    "    def initialize(self):\n",
    "        self.src_hidden = (torch.zeros(1, self.batch_size, self.hidden_dim),\n",
    "                           torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        self.trg_hidden = (torch.zeros(1, self.batch_size, self.hidden_dim),\n",
    "                           torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "model = TranslationRetrieval(src_vocab_len = 3, trg_vocab_len = 3, embedding_dim = 2, hidden_dim = 4, batch_size = 2)\n",
    "print torch.tensor([[0,1,2],[0,1,2]]).t()\n",
    "model.forward(torch.tensor([[0,1,0,0],[0,1,0,0]]).t(), torch.tensor([[1,0,1], [1,1,2]]).t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.119174408144\n",
      "199 0.0784459616407\n",
      "299 0.069283990073\n",
      "399 0.0646136462456\n",
      "499 0.0516234857496\n",
      "599 0.0524801849679\n",
      "699 0.0482873771107\n",
      "799 0.0439737692359\n",
      "899 0.0418169904151\n",
      "999 0.0392838096304\n",
      "1099 0.0380574452865\n",
      "1199 0.0377949607791\n",
      "1299 0.0333538646228\n",
      "1399 0.03543443323\n",
      "1499 0.035748228227\n",
      "1599 0.0338721896987\n",
      "1699 0.0327862428967\n",
      "1799 0.0337030412047\n",
      "1899 0.030920356483\n",
      "1999 0.0319915010186\n",
      "2099 0.0296992468066\n",
      "2199 0.0301666703017\n",
      "2299 0.0260528535\n",
      "2399 0.0262694187404\n",
      "2499 0.0259705003991\n",
      "2599 0.0326465129911\n",
      "2699 0.0255683002761\n",
      "2799 0.0231270299701\n",
      "2899 0.0238952251093\n",
      "2999 0.024560724647\n",
      "3099 0.0251003823942\n",
      "3199 0.022744486283\n",
      "3299 0.0220748823776\n",
      "3399 0.020469052688\n",
      "3499 0.0191370627726\n",
      "3599 0.0235361736704\n",
      "3699 0.0249580150266\n",
      "3799 0.0233411132649\n",
      "3899 0.0222041972738\n",
      "3999 0.0237440802011\n",
      "4099 0.0185055304464\n",
      "4199 0.0185835115699\n",
      "4299 0.0184142313519\n",
      "4399 0.0245127692615\n",
      "4499 0.0194680496352\n",
      "4599 0.0187962324417\n",
      "4699 0.0201208339713\n",
      "4799 0.0178982174693\n",
      "4899 0.0175141776708\n",
      "4999 0.027947948387\n",
      "5099 0.0169556685723\n",
      "5199 0.0200209002069\n",
      "5299 0.0183900172706\n",
      "5399 0.0229524254682\n",
      "5499 0.0184393183008\n",
      "5599 0.0147229774011\n",
      "5699 0.0154463683139\n",
      "5799 0.018403113907\n",
      "5899 0.014949102464\n",
      "5999 0.0156738885853\n",
      "6099 0.0165241888899\n",
      "6199 0.0146003304544\n",
      "6299 0.0170158230321\n",
      "6399 0.0128088537458\n",
      "6499 0.0147865861654\n",
      "6599 0.0147950775281\n",
      "6699 0.0148689685739\n",
      "6799 0.0117346790794\n",
      "6899 0.0180049838818\n",
      "6999 0.0134075016249\n",
      "7099 0.0132180820801\n",
      "7199 0.0188600535039\n",
      "7299 0.0157603991393\n",
      "7399 0.0147104784555\n",
      "7499 0.0150602188369\n",
      "7599 0.0155128035694\n",
      "7699 0.01687758966\n",
      "7799 0.0148900189379\n",
      "7899 0.0134952540102\n",
      "7999 0.0129556748288\n",
      "8099 0.0135615395848\n",
      "8199 0.012825073296\n",
      "8299 0.012287607562\n",
      "8399 0.0166218831728\n",
      "8499 0.0136230431963\n",
      "8599 0.0128333506291\n",
      "8699 0.011520469794\n",
      "8799 0.0119692342996\n",
      "8899 0.00918520148844\n",
      "8999 0.0118950702599\n",
      "9099 0.0187565052474\n",
      "9199 0.0177468507318\n",
      "9299 0.0137135756959\n",
      "9399 0.0133105632558\n",
      "9499 0.0149453465128\n",
      "9599 0.0109192575619\n",
      "9699 0.0102970746229\n",
      "9799 0.0133181946294\n",
      "9899 0.0115233942342\n",
      "9999 0.00954565024585\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "model = TranslationRetrieval(src_vocab_len = nwords_src, trg_vocab_len = nwords_trg, \n",
    "                             embedding_dim = 32, hidden_dim = 32, batch_size = batch_size)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MultiMarginLoss(reduction = \"sum\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for t in range(10000):\n",
    "    random.shuffle(train)\n",
    "    tot_loss = 0\n",
    "    for sid in range(0, len(train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        model.initialize()\n",
    "\n",
    "        src_list = [[0 for _ in range(MAX_SRC_LENGTH)] for _ in range(batch_size)]\n",
    "        trg_list = [[0 for _ in range(MAX_TRG_LENGTH)] for _ in range(batch_size)]\n",
    "        for i in range(batch_size):\n",
    "            src_sent, trg_sent = train[sid+i]\n",
    "            for j in range(len(src_sent)):\n",
    "                src_list[i][j] = src_sent[j]\n",
    "            for j in range(len(trg_sent)):\n",
    "                trg_list[i][j] = trg_sent[j] \n",
    "        src_list = torch.tensor(src_list).t()\n",
    "        trg_list = torch.tensor(trg_list).t()\n",
    "        src_pred, trg_pred = model(src_list, trg_list)\n",
    "        \n",
    "        matrix = torch.mm(src_pred.view(batch_size, -1), trg_pred.view(batch_size, -1).t())\n",
    "        loss = loss_fn(matrix, torch.tensor(range(batch_size)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tot_loss += loss.item()\n",
    "    if t%100 == 99:\n",
    "        print t, tot_loss/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 1, 0]), array([0.5, 1. , 4. ]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve(src, db_mtx):\n",
    "    scores = np.dot(db_mtx,src)\n",
    "    ranks = np.argsort(-scores)\n",
    "    return ranks, scores\n",
    "\n",
    "retrieve([0,0,1], [[1,1,0.5],[0.1,0,1],[0,0,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_matrix = []\n",
    "trg_matrix = []\n",
    "with torch.no_grad():\n",
    "    for sid in range(0, len(train), batch_size):\n",
    "        model.initialize()\n",
    "\n",
    "        src_list = [[0 for _ in range(MAX_SRC_LENGTH)] for _ in range(batch_size)]\n",
    "        trg_list = [[0 for _ in range(MAX_TRG_LENGTH)] for _ in range(batch_size)]\n",
    "        for i in range(batch_size):\n",
    "            src_sent, trg_sent = train[sid+i]\n",
    "            for j in range(len(src_sent)):\n",
    "                src_list[i][j] = src_sent[j]\n",
    "            for j in range(len(trg_sent)):\n",
    "                trg_list[i][j] = trg_sent[j] \n",
    "        src_list = torch.tensor(src_list).t()\n",
    "        trg_list = torch.tensor(trg_list).t()\n",
    "        src_pred, trg_pred = model(src_list, trg_list)\n",
    "        src_matrix += (src_pred.numpy()[0]).tolist()\n",
    "        trg_matrix += (trg_pred.numpy()[0]).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642578125\n"
     ]
    }
   ],
   "source": [
    "tot = 0.0\n",
    "for i in range(len(src_matrix)):\n",
    "    ranks, _ = retrieve(src_matrix[i], trg_matrix)\n",
    "    if i in ranks[:5]:\n",
    "        tot += 1\n",
    "print tot/len(src_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
