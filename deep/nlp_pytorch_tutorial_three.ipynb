{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.0269, -0.7684, -0.0047]]),\n",
       " tensor([[ 1.0225,  0.2555, -0.7867]]),\n",
       " tensor([[1.2509, 0.7152, 0.4489]]),\n",
       " tensor([[ 0.1487, -0.2523, -0.0829]]),\n",
       " tensor([[0.0560, 0.9337, 0.7852]])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = torch.nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2436, -0.1457, -0.4095]]], grad_fn=<CatBackward>)\n",
      "tensor([[-0.2436, -0.1457, -0.4095]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "lstm = torch.nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "inputs\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = None\n",
    "\n",
    "for i in inputs:\n",
    "    if hidden:\n",
    "        out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    else:\n",
    "        out, hidden = lstm(i.view(1, 1, -1))\n",
    "print out\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "out, hidden = lstm(inputs)\n",
    "print out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['everybody', 'ate', 'apple', 'that', 'read', 'dog', 'book', 'the'])\n",
      "{'everybody': 1, 'ate': 2, 'apple': 3, 'that': 4, 'read': 5, 'dog': 6, 'PADDING': 0, 'book': 7, 'the': 8}\n",
      "[[8, 6, 2, 8, 3, 0], [1, 5, 4, 7, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    (\"The dog ate the apple\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".lower().split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "vocab = set(reduce(lambda x, y : x+y, [t[0] for t in training_data] ) )\n",
    "print vocab\n",
    "word_to_ix = {word: i+1 for i, word in enumerate(vocab)}\n",
    "word_to_ix[\"PADDING\"] = 0\n",
    "tag_to_ix = {\"DET\": 1, \"NN\": 2, \"V\": 3, \"PADDING\":0}\n",
    "max_sentence_length = max([len(t[0]) for t in training_data]) + 1 #plus one for some extra protection\n",
    "training_sentences = []\n",
    "training_tags = []\n",
    "for t in training_data:\n",
    "    words, tags = t\n",
    "    training_sentences.append([0 for i in xrange(max_sentence_length)])\n",
    "    training_tags.append([0 for i in xrange(max_sentence_length)])\n",
    "    for j, word in enumerate(words):\n",
    "\n",
    "        training_sentences[-1][j] = word_to_ix[word]\n",
    "        training_tags[-1][j] = tag_to_ix[tags[j]]\n",
    "        \n",
    "print(word_to_ix)\n",
    "print training_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1534, -0.7874, -1.4722]],\n",
       "\n",
       "        [[-1.1669, -0.7750, -1.4785]],\n",
       "\n",
       "        [[-1.1825, -0.7322, -1.5482]],\n",
       "\n",
       "        [[-1.1703, -0.7501, -1.5260]],\n",
       "\n",
       "        [[-1.1532, -0.7662, -1.5160]],\n",
       "\n",
       "        [[-1.1954, -0.7654, -1.4599]]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, sentence_length):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sentence_length = sentence_length\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input).view(self.sentence_length,1,-1)\n",
    "        out, hidden = self.lstm(embedded)\n",
    "        out = self.hidden2tag(out)\n",
    "        return F.log_softmax(out, dim=2)\n",
    "    \n",
    "lstm = LSTMTagger(4, 4, len(vocab)+1, 3, max_sentence_length)\n",
    "lstm(torch.tensor(training_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 0.435446375627\n",
      "399 0.00839321744977\n",
      "599 0.00338593649911\n",
      "799 0.00184002554597\n",
      "999 0.00110415017567\n"
     ]
    }
   ],
   "source": [
    "step_size = 200\n",
    "lstm = LSTMTagger(4, 4, len(vocab)+1, 4, max_sentence_length)\n",
    "loss_fn = torch.nn.NLLLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-2)\n",
    "\n",
    "total_losses = 0\n",
    "for t in range(1000):\n",
    "\n",
    "\n",
    "    for i, data in enumerate(training_data): \n",
    "        _, tags = data\n",
    "        lstm.zero_grad()\n",
    "        output = lstm(torch.tensor(training_sentences[i])).view(max_sentence_length,-1)\n",
    "\n",
    "        loss = loss_fn(output, torch.tensor(training_tags[i]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_losses += loss.item()\n",
    "    if t%step_size == step_size - 1:\n",
    "        print t, total_losses/step_size\n",
    "        total_losses = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_sentence = \"Everybody that ate the dog read\".lower().split()\n",
    "    test = [0 for _ in range(max_sentence_length)]\n",
    "    for i, word in enumerate(test_sentence):\n",
    "        test[i] = word_to_ix[word]\n",
    "    output = lstm(torch.tensor(test))\n",
    "    print torch.argmax(output, dim = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# On Off Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3820]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OOGate(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(OOGate, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        #self.lstm = torch.nn.LSTM(1, hidden_dim)\n",
    "        self.input2hidden = torch.nn.Linear(1+hidden_dim, hidden_dim)\n",
    "        self.hidden2out = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.init_hidden()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = torch.cat((input.view(1,1,-1), self.hidden), dim = 2)\n",
    "        self.hidden = torch.tanh(self.input2hidden(input))\n",
    "        # print input, self.hidden\n",
    "        #out, self.hidden = self.lstm(input.view(1,1,1) , self.hidden)\n",
    "        out = self.hidden2out(self.hidden)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        self.hidden = torch.zeros(1, 1, self.hidden_dim)\n",
    "    \n",
    "oog = OOGate(2)\n",
    "oog(torch.tensor([1.]))\n",
    "oog(torch.tensor([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4174]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OOGate(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(OOGate, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = torch.nn.LSTM(1, hidden_dim)\n",
    "        self.hidden2out = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.init_hidden()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out, self.hidden = self.lstm(input.view(1,1,1) , self.hidden)\n",
    "        out = self.hidden2out(out)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        self.hidden = (torch.zeros(1, 1, self.hidden_dim), torch.zeros(1, 1, self.hidden_dim))\n",
    "    \n",
    "oog = OOGate(2)\n",
    "oog(torch.tensor([1.]))\n",
    "oog(torch.tensor([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 28.9553382313\n",
      "199 23.3272681677\n",
      "299 12.5970495993\n",
      "399 4.93867952798\n",
      "499 2.64991111517\n",
      "599 2.38410795055\n",
      "699 1.91620930389\n",
      "799 1.35203151017\n",
      "899 1.11320277214\n",
      "999 0.994828743935\n",
      "1099 0.928690083027\n",
      "1199 0.904541380405\n",
      "1299 0.888615362942\n",
      "1399 0.836193180084\n",
      "1499 0.852169306874\n",
      "1599 0.834107281864\n",
      "1699 0.839946219325\n",
      "1799 0.816154349148\n",
      "1899 0.821465983391\n",
      "1999 0.816941514611\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "possibilities = [0.0 for i in range(128)]\n",
    "for i in range(128):\n",
    "    j = i%4\n",
    "    if j < 2: \n",
    "        possibilities[i] = 1.0\n",
    "        \n",
    "step_size = 100\n",
    "oog = OOGate(4)\n",
    "\n",
    "loss_fn = torch.nn.BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(oog.parameters(), lr=1e-2)\n",
    "\n",
    "total_losses = 0\n",
    "for t in range(2000):\n",
    "    \n",
    "    while True:\n",
    "        a = random.randint(0,127)\n",
    "        b = random.randint(0,126)\n",
    "        if a < b:\n",
    "            try:\n",
    "                example = possibilities[a:b+1]\n",
    "                break\n",
    "            except IndexError:\n",
    "                pass\n",
    "    # print example\n",
    "    oog.zero_grad()\n",
    "    oog.init_hidden()\n",
    "    loss = torch.tensor([0.])\n",
    "    # print example\n",
    "    for i in range(len(example) -1): \n",
    "        # print \"i\", i, data\n",
    "        oog.zero_grad()\n",
    "        output = oog(torch.tensor([example[i]]))\n",
    "        y = example[i+1]\n",
    "        \n",
    "        loss += loss_fn(output, torch.tensor([[y]]))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_losses += loss.item()\n",
    "    if t%step_size == step_size - 1:\n",
    "        print t, total_losses/step_size\n",
    "        total_losses = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([[[0.6244]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0002]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0012]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9937]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9948]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0005]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0022]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9989]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9967]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0013]]], grad_fn=<SigmoidBackward>)\n",
      "0 tensor([[[0.0023]]], grad_fn=<SigmoidBackward>)\n",
      "1 tensor([[[0.9991]]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "oog.init_hidden()\n",
    "print 1, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([1.]))\n",
    "print 0, oog(torch.tensor([0.]))\n",
    "print 1, oog(torch.tensor([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
